{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3ddd66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'pd_speech_features.csv' downloaded successfully!\n",
      "CSV loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/dcleres/Parkinson_Disease_ML/refs/heads/master/pd_speech_features.csv'\n",
    "file_name = 'pd_speech_features.csv'\n",
    "\n",
    "# Download the file using requests\n",
    "try:\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()  # Check if the request was successful\n",
    "    with open(file_name, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "    print(f\"File '{file_name}' downloaded successfully!\")\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Error: Failed to download or find the file '{file_name}'. Exception: {e}\")\n",
    "\n",
    "# Load the CSV\n",
    "try:\n",
    "    pd_speech_features = pd.read_csv(file_name)\n",
    "    print(\"CSV loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading the CSV: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e09e997f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "0     64.0\n",
      "1    188.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "header = pd_speech_features.iloc[0]\n",
    "pd_speech_features = pd_speech_features[1:] # removing header row\n",
    "pd_speech_features.columns = header # Set column header\n",
    "pd_speech_features.head()\n",
    "\n",
    "\n",
    "pd_speech_features.describe()\n",
    "\n",
    "print(pd_speech_features.groupby('class').size()/3)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15b9df84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Features shape: (756, 752)\n",
      "Labels shape: (756,)\n",
      "Person IDs shape: (756,)\n"
     ]
    }
   ],
   "source": [
    "# Step 1.2: Separate important columns\n",
    "# Convert to correct types\n",
    "pd_speech_features = pd_speech_features.apply(pd.to_numeric)\n",
    "\n",
    "pd_speech_features =  pd_speech_features.astype(float) #per default all floats\n",
    "pd_speech_features[['id', 'numPulses', 'numPeriodsPulses']] = pd_speech_features[['id', 'numPulses', 'numPeriodsPulses']].astype(int)\n",
    "pd_speech_features[['gender', 'class']] = pd_speech_features[['gender', 'class']].astype('category')\n",
    "pd_speech_features.dtypes\n",
    "\n",
    "\n",
    "labels = pd_speech_features['class'].astype(int)   # 0 or 1 (Healthy or PD)\n",
    "person_ids = pd_speech_features['id'].astype(int)  # Each person's ID for LOPO\n",
    "all_features = pd_speech_features.drop(['id', 'gender', 'class'], axis=1)\n",
    "\n",
    "\n",
    "# Step 1.3: Normalize features (MinMax scaling)\n",
    "scaler = MinMaxScaler()\n",
    "all_features_scaled = pd.DataFrame(scaler.fit_transform(all_features), columns=all_features.columns)\n",
    "\n",
    "print(\"All Features shape:\", all_features_scaled.shape)\n",
    "print(\"Labels shape:\", labels.shape)\n",
    "print(\"Person IDs shape:\", person_ids.shape)\n",
    "\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31d11e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total folds (equal to total unique persons): 252\n",
      "✅ GPU(s) detected: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 13325330976622364165\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3676307456\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 11416159335405154944\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3050 6GB Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Step 2.1: Setup LOPO-CV\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "# Step 2.2: Create splits\n",
    "splits = logo.split(all_features_scaled, labels, groups=person_ids)\n",
    "\n",
    "# Check how many folds\n",
    "print(f\"Total folds (equal to total unique persons): {len(np.unique(person_ids))}\")\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# ✅ GPU Check\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(\"✅ GPU(s) detected:\", gpus)\n",
    "    # try:\n",
    "    #     for gpu in gpus:\n",
    "    #         tf.config.set_memory_growth(gpu, True)  # ✅ Use stable API\n",
    "    # except RuntimeError as e:\n",
    "    #     print(\"Memory growth setting failed:\", e)\n",
    "else:\n",
    "    print(\"⚠️ No GPU found. Training will run on CPU.\")\n",
    "\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c48def27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Step 3.1: Define a simple 9-layer CNN for feature-level combination\n",
    "def build_feature_level_cnn(input_shape):\n",
    "    model = Sequential()\n",
    "\n",
    "    # First Conv block\n",
    "    model.add(Conv1D(32, kernel_size=8, activation='relu', input_shape=input_shape, kernel_regularizer=l2(0.001)))\n",
    "    model.add(Conv1D(32, kernel_size=8, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "    # Second Conv block\n",
    "    model.add(Conv1D(64, kernel_size=8, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "    model.add(Conv1D(64, kernel_size=8, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "    # Third Conv block\n",
    "    model.add(Conv1D(128, kernel_size=8, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "    model.add(Conv1D(128, kernel_size=8, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "    # Dense and output\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # Binary output\n",
    "\n",
    "    # Compile\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598fdb75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total LOPO folds: 252\n",
      "\n",
      "🔄 Fold 1 / 252: Training...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, matthews_corrcoef\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "# Prepare LOPO\n",
    "logo = LeaveOneGroupOut()\n",
    "splits = logo.split(all_features_scaled, labels, groups=person_ids)\n",
    "\n",
    "# Create full list of splits once\n",
    "all_splits = list(splits)\n",
    "total_folds = len(all_splits)\n",
    "\n",
    "print(f\"Total LOPO folds: {total_folds}\")\n",
    "\n",
    "# Initialize trackers\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    " # Initialize trackers\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "# Run first half\n",
    "for fold_counter, (train_idx, test_idx) in enumerate(all_splits, start=1):\n",
    "    print(f\"\\n🔄 Fold {fold_counter} / {total_folds}: Training...\")\n",
    "\n",
    "    X_train, X_test = all_features_scaled.iloc[train_idx], all_features_scaled.iloc[test_idx]\n",
    "    y_train, y_test = labels.iloc[train_idx], labels.iloc[test_idx]\n",
    "\n",
    "    X_train = np.expand_dims(X_train.values, axis=2)\n",
    "    X_test = np.expand_dims(X_test.values, axis=2)\n",
    "\n",
    "    model = build_feature_level_cnn(input_shape=(X_train.shape[1], 1))\n",
    "    model.fit(X_train, y_train, epochs=200, batch_size=16, verbose=0)\n",
    "\n",
    "    y_pred = (model.predict(X_test).flatten() > 0.5).astype(int)\n",
    "\n",
    "    all_preds.extend(y_pred)\n",
    "    all_labels.extend(y_test)\n",
    "\n",
    "    print(f\"✅ Fold {fold_counter}: Accuracy = {accuracy_score(y_test, y_pred):.4f}\")\n",
    "\n",
    "\n",
    "# Evaluate half results\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "f1 = f1_score(all_labels, all_preds)\n",
    "mcc = matthews_corrcoef(all_labels, all_preds)\n",
    "\n",
    "print(f\"\\n🚩 Full LOPO Results:\")\n",
    "print(f\"🔹 Accuracy : {accuracy:.4f}\")\n",
    "print(f\"🔹 F1-Score : {f1:.4f}\")\n",
    "print(f\"🔹 MCC      : {mcc:.4f}\")\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
